[
  {
    "path": "posts/2021-09-15-blog-post-1-read-in-data/",
    "title": "blog post 1: reading in data",
    "description": "practicing the unsexy first step of data analysis",
    "author": [
      {
        "name": "Claire Battaglia",
        "url": {}
      }
    ],
    "date": "2021-09-15",
    "categories": [],
    "contents": "\r\nreading in the data\r\nThe first step in any project is going to be reading in the data. It’s not glamorous but without it we’d be stuck trying to make sense of a messy spreadsheet forever. For this first post, I’ll use the data set “organiceggpoultry.xls.”\r\n\r\n\r\n# set working directory\r\nsetwd(\"../../_data\")\r\n\r\n# assign data to variable\r\ncogEggs <- read_excel(\"organiceggpoultry.xls\")\r\n\r\n\r\n\r\nunderstanding its shape\r\nOnce we’ve read the data in, we’ll use a few commands to get a birds-eye view of what we’re looking at. Getting the dimensions is a good place to start.\r\n\r\n\r\n# get dimensions\r\ndim(cogEggs)\r\n\r\n\r\n[1] 124  11\r\n\r\nThis means that there are 124 rows and 11 columns. In other words, there are 11 variables and 124 observances.\r\nNext, let’s preview the data set.\r\n\r\n\r\n# preview first 5 rows\r\nhead(cogEggs)\r\n\r\n\r\n# A tibble: 6 x 11\r\n  `(Certified Organ~ ...2   ...3  ...4  ...5  ...6  ...7   ...8  ...9 \r\n  <chr>              <chr>  <chr> <chr> <chr> <lgl> <chr>  <chr> <chr>\r\n1 <NA>                <NA>   <NA>  <NA>  <NA> NA    <NA>   <NA>  <NA> \r\n2 USDA Certified Or~  <NA>   <NA>  <NA>  <NA> NA    USDA ~ <NA>  <NA> \r\n3 Price per Carton ~  <NA>   <NA>  <NA>  <NA> NA    Price~ <NA>  <NA> \r\n4 <NA>               \"Extr~ \"Ext~ \"Lar~ \"Lar~ NA    Whole  B/S ~ Bone~\r\n5 Jan 2004           \"230\"  \"132\" \"230\" \"126\" NA    197.5  645.5 too ~\r\n6 February           \"230\"  \"134~ \"226~ \"128~ NA    197.5  642.5 too ~\r\n# ... with 2 more variables: ...10 <chr>, ...11 <chr>\r\n\r\nyikes!\r\nUsing the colnames() function will show us the names of all 11 columns, which may help us better understand what we’re looking at.\r\n\r\n\r\n# get column names\r\ncolnames(cogEggs)\r\n\r\n\r\n [1] \"(Certified Organic denotes products grown and processed according to USDA's national organic standards and certified by USDA-accredited State and private certification organizations.)\"\r\n [2] \"...2\"                                                                                                                                                                                   \r\n [3] \"...3\"                                                                                                                                                                                   \r\n [4] \"...4\"                                                                                                                                                                                   \r\n [5] \"...5\"                                                                                                                                                                                   \r\n [6] \"...6\"                                                                                                                                                                                   \r\n [7] \"...7\"                                                                                                                                                                                   \r\n [8] \"...8\"                                                                                                                                                                                   \r\n [9] \"...9\"                                                                                                                                                                                   \r\n[10] \"...10\"                                                                                                                                                                                  \r\n[11] \"...11\"                                                                                                                                                                                  \r\n\r\nSomething tells me that these are not actually the names of the columns.\r\nselecting specific columns\r\nSelecting a specific column to preview might help us understand what the column names should be.\r\n\r\n\r\n# preview first 5 rows of column 2\r\nhead(select(cogEggs, \"...2\"))\r\n\r\n\r\n# A tibble: 6 x 1\r\n  ...2                 \r\n  <chr>                \r\n1  <NA>                \r\n2  <NA>                \r\n3  <NA>                \r\n4 \"Extra Large \\nDozen\"\r\n5 \"230\"                \r\n6 \"230\"                \r\n\r\nnope! This data set is going to need some work. More next week!\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-09-21T17:32:08-04:00",
    "input_file": "blog-post-1-read-in-data.knit.md"
  },
  {
    "path": "posts/2021-09-15-lets-try-a-blog-shall-we/",
    "title": "Let's try a blog, shall we?",
    "description": "Homework 1, trying to get a blog up without breaking the whole class website.",
    "author": [
      {
        "name": "Joe Davis",
        "url": {}
      }
    ],
    "date": "2021-09-14",
    "categories": [
      "-homework 1 -Joe Davis"
    ],
    "contents": "\r\nSo, This is blogging in Rmarkdown.\r\nDo we still call it blogging? Substacking in front of the paywall?\r\nMy introduction information was included on the post card excercise, so how about a little aside first? I’ve always preferred to write in a conversational tone. This is a much more common approach in my professional environs to which I’ve grown accustomed. Obviously, this a poor fit for the academic world. I promise I will return to using only my most serious and authoritative written voice tout suite. Well, probably not right away, but as soon as I feel like I know what I’m doing here and not breaking things.\r\nI plan on attempting to read in some of the messy data sets in the next installment of the blog, but for getting the hang of things here I think it’s best for us all if I do some things with the training wheels on first.\r\nLet’s start with an R code chunk doing some basic stuff while showing the R code along with it.\r\n\r\n\r\n# Making up a vector for liverpool football club goals scored \r\nliverpool_goals <- c(2,1,3,4)\r\n\r\n# Getting the mean of the made up vector of LFC goals\r\nmean(liverpool_goals)\r\n\r\n\r\n[1] 2.5\r\n\r\nThat seems to have worked! Alright, let’s take another baby step forward. Let’s try and get the already cleaned up Australian marriage data file into this post and look at some of the columns.\r\n\r\n\r\n# Loading in and assigning in the Australian marriage data. I copied the .csv from the existing _data folder to the files folder for this post. Hopefully that's the right thing to do!\r\naustralian_marriage_data <- read_csv(file = \"lets-try-a-blog-shall-we_files/australian_marriage_tidy.csv\")\r\naustralian_marriage_data\r\n\r\n\r\n# A tibble: 16 x 4\r\n   territory                       resp    count percent\r\n   <chr>                           <chr>   <dbl>   <dbl>\r\n 1 New South Wales                 yes   2374362    57.8\r\n 2 New South Wales                 no    1736838    42.2\r\n 3 Victoria                        yes   2145629    64.9\r\n 4 Victoria                        no    1161098    35.1\r\n 5 Queensland                      yes   1487060    60.7\r\n 6 Queensland                      no     961015    39.3\r\n 7 South Australia                 yes    592528    62.5\r\n 8 South Australia                 no     356247    37.5\r\n 9 Western Australia               yes    801575    63.7\r\n10 Western Australia               no     455924    36.3\r\n11 Tasmania                        yes    191948    63.6\r\n12 Tasmania                        no     109655    36.4\r\n13 Northern Territory(b)           yes     48686    60.6\r\n14 Northern Territory(b)           no      31690    39.4\r\n15 Australian Capital Territory(c) yes    175459    74  \r\n16 Australian Capital Territory(c) no      61520    26  \r\n\r\nIf there’s a table above this sentence, then that’s just a little bit of internet magic. The thing about tables, though, is that sometimes it becomes hard to see the forest for the trees. Some graphs, then? I want to just look at the percent of yes votes by territory from the overall data set.\r\n\r\n\r\n#set a data frame from a portion of the tidy spreadsheet, filtering to yes votes\r\naustralian_filter <- filter(australian_marriage_data, resp == \"yes\")\r\n\r\n#using select to drop the variable I don't want to look at\r\naustralian_df <- select(australian_filter, -(resp:count))\r\n\r\n#simple scatter plot of the yes vote percentage for each territory\r\nggplot(data = australian_df) +\r\n  geom_point(mapping = aes(x = territory, y = percent))\r\n\r\n\r\n\r\n\r\nI’ll come back to do something more interesting and coherent for analysis in a future installment, but I’m already starting to feel a lot more comfortable with the R verbiage and such. I’m sure there were more efficient ways to make that graph but we’ll get to that later I’m sure.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-09-15-lets-try-a-blog-shall-we/lets-try-a-blog-shall-we_files/figure-html5/some basic graphs of that data-1.png",
    "last_modified": "2021-09-21T17:32:10-04:00",
    "input_file": "lets-try-a-blog-shall-we.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to DACSS 601",
    "description": "Welcome to DACSS 601: Foundations of Data Science. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Meredith Rolfe",
        "url": "http://umass.edu/sbs/dacss"
      }
    ],
    "date": "2021-03-25",
    "categories": [
      "welcome"
    ],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-09-21T17:32:12-04:00",
    "input_file": "welcome.knit.md"
  }
]
